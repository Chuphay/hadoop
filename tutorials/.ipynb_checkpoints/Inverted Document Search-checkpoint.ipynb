{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted Document Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we explore how to find documents that contain a specific word. \n",
    "\n",
    "One way to do that is to simply scan through every document and see if the word is contained in that document. This will work well if you are only going to do this type of search once or twice, but what if this kind of search is something that you need to do often?\n",
    "\n",
    "We need a better way to do this type of search, so that we can first create a data structure that supports this type of search. Then once we make the data set, we can quickly find which documents are contained, rather than having to search through all the documents all together every time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###An Example\n",
    "\n",
    "Let's take a look at an example, to make sure we know what we are talking about. Suppose you have the following three documents with their content:\n",
    "\n",
    "<p style =\"color:red\"> Document 1:</p> The big cat ate the small dog.\n",
    "\n",
    "<p style =\"color:red\">Document 2:</p> My cat has black eyes.\n",
    "\n",
    "<p style =\"color:red\">Document 3:</p> For lunch we ate black beans.\n",
    "\n",
    "\n",
    "\n",
    "If we were to search for \"cat\", both document 1 and document 2 would be returned, whereas if we searched for lunch, only document 3 would be returned.\n",
    "\n",
    "So Now, what we want to do is first create a data structure that will help us do this kind of search more easily.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So basically we want to ask our algorithm given keywords which documents will match our query the best. So we want to make an inverteed index\n",
    "\n",
    "<table>\n",
    "<tr><td style = \"color:blue\">Words</td><td style=\"color:red\" colspan=3>Documents</td><tr>\n",
    "<tr><td>the</td><td></td><td>doc 1</td><td>doc 1</td><tr>\n",
    "<tr><td>big</td><td></td><td>doc 1</td><tr>\n",
    "<tr><td>cat</td><td></td><td>doc 1</td><td>doc 2</td><tr>\n",
    "<tr><td>ate</td><td></td><td>doc 1</td><td>doc 3</td><tr>\n",
    "<tr><td>small</td><td></td><td>doc 1</td><tr>\n",
    "<tr><td>dog</td><td></td><td>doc 1</td><tr>\n",
    "<tr><td>my</td><td></td><td>doc 2</td><tr>\n",
    "<tr><td>has</td><td></td><td>doc 2</td><tr>\n",
    "<tr><td>black</td><td></td><td>doc 2</td><td>doc 3</td><tr>\n",
    "<tr><td>eyes</td><td></td><td>doc 2</td><tr>\n",
    "<tr><td>for</td><td></td><td>doc 3</td><tr>\n",
    "<tr><td>lunch</td><td></td><td>doc 3</td><tr>\n",
    "<tr><td>we</td><td></td><td>doc 3</td><tr>\n",
    "<tr><td>beans</td><td></td><td>doc 3</td><tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making this inverted index, it is now easy to search for which documents contain a specific word without having to revert to scanning all the documents. This is why I call this kind of search an inverted document search, because insted of searching a document for certain words, we are going to search for which words are contained in a document... (if that made any sense.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The Algorithm\n",
    "\n",
    "If you have been following along with the other tutorials in this series, you should probably farly confident in how to program a map-reduce job to create the inverted index, each mapper will scan through a document and find the words in that document. For example, if the first mapper was in charge of reading over the first document in our example above, then the output from the mapper would be:\n",
    "\n",
    "<p style =\"color:red\"> the -- Document 1 -- 2</p>  \n",
    "<p style =\"color:red\"> big -- Document 1 -- 1</p>\n",
    "<p style =\"color:red\"> cat -- Document 1 -- 1</p>\n",
    "<p style =\"color:red\"> ate -- Document 1 -- 1</p>\n",
    "<p style =\"color:red\"> small -- Document 1 -- 1</p>\n",
    "<p style =\"color:red\"> dog -- Document 1 -- 1</p>\n",
    "\n",
    "Where the 2 following \"the\" occurs because 2 occured twice in document 1.\n",
    "\n",
    "The reducer, obviously combines the results together. \n",
    "\n",
    "As always, I recommend you try to program this up yourself, but as a source of reference, here's my code:\n",
    "\n",
    "Mapper:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "file_name = os.environ['mapreduce_map_input_file'] #This allows us to know which file we are currently mapping upon\n",
    "file_start = os.environ['mapreduce_map_input_start'] #We are not using this, but it may be useful for other tasks\n",
    "file_length = os.environ['mapreduce_map_input_length'] #We are not using this either\n",
    "\n",
    "myDict = {}\n",
    "for line in sys.stdin:\n",
    "    words = [i for i in re.split(r'\\W+',line.lower()) if i]\n",
    "    for word in words:\n",
    "        try:\n",
    "            myDict[word] += 1\n",
    "        except KeyError:\n",
    "            myDict[word] = 1\n",
    "\n",
    "for word in myDict:\n",
    "    print word, file_name, myDict[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the reducer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "data = {}\n",
    "for line in sys.stdin:\n",
    "    word, file_name, num = line.split()\n",
    "    try:\n",
    "        data[word][file_name] = num\n",
    "    except KeyError:\n",
    "        data[word] = {file_name:num}\n",
    "\n",
    "for word in data:\n",
    "    out = [word]\n",
    "    for file_name in data[word]:\n",
    "        out.append(file_name)\n",
    "        out.append(data[word][file_name])\n",
    "    out = \" \".join(out)\n",
    "    print out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Term Search\n",
    "\n",
    "Now, let us write a mapreduce job to search for the documents that contain a certain word or even better words.\n",
    "\n",
    "What we first have to do is copy the output from the previous step into a new folder, because we will need to access that data obviously. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing that, it is fairly straightforward to search for at least one word, I will leave it up to you how to search for more than one word, and the implications that that contains.\n",
    "\n",
    "In fact, this is a mapreduce job that does not need any reducers. I believe this is the first time we have done a map reduce job without a reducer, so the way we call the streaming file will change.\n",
    "\n",
    "Here is the mapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if(len(sys.argv)<2):\n",
    "    print \"Need to supply a list of words to search for\"\n",
    "    sys.exit(1)\n",
    "list_of_words = sys.argv[1:]\n",
    "\n",
    "for line in sys.stdin:\n",
    "    words = line.split()\n",
    "    if words[0] in list_of_words:\n",
    "    print line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need a reducer for this map reduce job, and we specify this by calling hadoop in the following way:\n",
    "\n",
    "```\n",
    "hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.5.2.jar -D mapred.reduce.tasks=0 -file term_finder.py -mapper \"python term_finder.py is cat coffee\" -input /user/hduser/terms/* -output /user/hduser/out_tests2\n",
    "```\n",
    "Finally, the output for this example, using a small data set is like\n",
    "\n",
    "\n",
    "```\n",
    "is hdfs://localhost:54310/user/hduser/words/file0.txt 1 hdfs://localhost:54310/user/hduser/words/file5.txt 1 hdfs://localhost:54310/user/hduser/words/file4.txt 1\t\n",
    "\t\n",
    "cat hdfs://localhost:54310/user/hduser/words/file4.txt 1\t\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
